<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>All roads lead to PyKX - Habla computing Blog</title>
    <link rel="stylesheet" href="/assets/css/app.css">
    <link rel="shortcut icon" type="image/png" href="/favicon.png" />
    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
    <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>All roads lead to PyKX | Habla computing Blog</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="All roads lead to PyKX" />
<meta name="author" content="Jesús López-González" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="All Roads Lead to Kdb: A Python to Production tale Introducing Emma Monad, the main character of our story and CTO of Mad Flow, a large and fictional company dedicated to improving the quality of life in Madrid. Emma was facing the real-world challenge of tackling the issue of heavy traffic in the city. However, she found herself grappling with an outdated, ad-hoc constructed, somewhat inflexible, Mad Flow infrastructure stack. It was a code base that incorporated various modules developed over time, by in-house data science, engineering and developer teams with the help of occasional interns from the nearby university. The application was predominantly built in Python, the most popular programming language of data science over the last decade. However, there were problems with the infrastructure. While open and customizable, it suffered with chaotic organization and frequent performance issues, meaning it was slow and unwieldy when incorporating new traffic data-sets or building new insights quickly. This combined to hinder their ability to define and progress effective transport solutions for the city. Emma wanted to take the greatness of the Mad Flow code base, unlock its true potential, and help fulfil its and their mission of transforming Madrid into a more pleasant, efficient and environmentally friendly city. Emma thus wanted more agile data management and effective production-ready analytics easily deployed. She had heard, via some occasional consultants to her organization, about a popular and seemingly blindingly fast time-series database and analytics platform called kdb. Nevertheless, that was not for her she felt. Her team’s comfort was in Python, the language that Mad Flow was predominantly written in, and it was simply impractical to build in anything else, so Python it was. However, at a local PyData Meetup Emma attended, a data scientist acquaintance told her over drinks about PyKX, an open-source library allowing Python to remain the guiding language, but harnessing the power of kdb at runtime. She decided to give it a try, and as time proved, PyKX just worked, and was indispensable in guiding the team from taking a predominantly ad-hoc research data and analytics codebase into a production powerhouse. The rest of this story tells you how and why. Chapter 1: I just want to stay in Python Setting up kdb to ingest the traffic data, Emma feared, might require several weeks. Somewhat apprehensively, Emma set expectations with her team accordingly. However, there she was, with a skilled Python team that had no prior experience in writing even a simple “Hello World” in Q (which, by the way, is 0N!”Hello World!”), and a Python REPL waiting for instructions. She tried to conceal her fear, and she typed the very first line of PyKX code in the Python shell: &gt;&gt;&gt; import pykx as kx A sense of calm washed over her as she saw that everything was going well. Madrid has many traffic devices scattered throughout the city, so her first task was to retrieve their information, available in several .csv files, into the new platform. According to the PyKX documentation, the pykx.read attribute seemed to be her best option: tdevices = kx.q.read.csv(&quot;devices.csv&quot;, types = &quot;JFFJJSSS&quot;, delimiter=&quot;;&quot;, as_table=True) Her team had extensive familiarity with Pandas notation, so she decided to try some Pandas instructions to retrieve a few columns from the table. It worked effortlessly, or at least it seemed so at first. &gt;&gt;&gt; tdevices[[&#39;district&#39;, &#39;id&#39;, &#39;latitude&#39;, &#39;longitude&#39;]] pykx.List(pykx.q(&#39; 4 4 1 4 4 4 1 7 .. 3840 3841 3842 3843 3844 3845 3846 3847 .. 40.4305 40.43052 40.42213 40.42143 40.43378 40.42351 40.42816 40.42879.. -3.688323 -3.687256 -3.691727 -3.691929 -3.68847 -3.690991 -3.698403 -3.69455.. &#39;)) “Yikes!” It was so close, but it didn’t look like a dataframe. “Where are my columns?” she thought. That wouldn’t impress her colleagues, for whom familiar columns mattered. If this was to be a barrier, then it would likely be even harder to run the required analytics algorithms on the proposed new platform. But the documentation suggested the pdcommand which just worked: &gt;&gt;&gt; tdevices.pd()[[&#39;district&#39;, &#39;id&#39;, &#39;longitude&#39;, &#39;latitude&#39;]] district id longitude latitude 0 4 3840 -3.688323 40.430502 1 4 3841 -3.687256 40.430524 2 1 3842 -3.691727 40.422132 ... ... ... ... ... 4741 16 6933 -3.672497 40.484118 4742 16 7129 -3.672500 40.484181 4743 16 7015 -3.672308 40.485002 [4744 rows x 4 columns] Et voilà! Emma simply had to repeat the process to load the remaining dataframes used by the selected algorithm, and she could execute the program smoothly, in its very original form. She had intentionally choose an algorithm that produced output in the form of familiar CSV file standards because that was what she and her team knew, but her PyData and kdb-knowledgeable fellow attendee had told her that kdb data stores were so much more efficient. For now, though, she’d stay with csv. Nonetheless, this marked a significant milestone. Emma had already felt that some of the initial promises were delivered! However, she was well aware of the long road ahead of her if she was to bring along her team and make Mad Flow the agile production analytics platform she wanted it to be. Chapter 2: From Zero to Hero Several weeks passed, and, having onboarded a couple of data scientist interns, she finally found time to work with them and conduct more research on PyKX. “Do as little work as necessary,” she murmured. “I just want my team to work with what they’re comfortable with, but have kdb do the heavy lifting!” Emma repeated these mantras from the PyKX user guide to herself whenever she was tempted to use pd. Indeed, she was now well aware that in order to fully harness the platform’s potential, she should minimize data transfers between the two realms, and delegate as much work as possible to the kdb infrastructure. The key to achieving these goals lay in leveraging the PyKX object API, which allowed a Python-first approach. This API made it easy to embed q/kdb within Python, enabling the direct use of efficient q functions in Python code. Additionally, it provided convenient re-implementations of Pythonic APIs, like the Pandas APIs, eliminating the need for conversions to Pandas in many cases. If feasible, this would enhance the development experience, reduce the chances of errors, and, the team hoped, significantly improve performance. She first tried with the PyKX Pandas API re-implementation, which could be actrivated through the following environment variable: &gt;&gt;&gt; import os &gt;&gt;&gt; os.environ[&#39;PYKX_ENABLE_PANDAS_API&#39;] = &#39;true&#39; Then, she tried the exact same Pandas expression as in the previous section: &gt;&gt;&gt; tdevices[[&#39;district&#39;, &#39;id&#39;, &#39;latitude&#39;, &#39;longitude&#39;]] pykx.Table(pykx.q(&#39; district id latitude longitude -------------------------------- 4 3840 40.4305 -3.688323 4 3841 40.43052 -3.687256 1 3842 40.42213 -3.691727 4 3843 40.42143 -3.691929 4 3844 40.43378 -3.68847 ... &#39;)) Et voilà! There were the columns, and she didn’t need to convert q tables to Pandas dataframes! “Do as little work as necessary?” Nailed it! And this approach worked for many other methods of the Pandas API as well, such as filtering, dropping, and renaming columns. &gt;&gt;&gt; tdevices = tdevices[tdevices[&quot;elem_type&quot;] == &quot;URB&quot;] &gt;&gt;&gt; tdevices = tdevices.drop([&quot;elem_type&quot;,&quot;district&quot;, &quot;cod_cent&quot;, &quot;name&quot;, &quot;utm_x&quot;, &quot;utm_y&quot;], axis=1) &gt;&gt;&gt; tdevices = tdevices.rename(columns={&quot;longitude&quot;:&quot;long&quot;, &quot;latitude&quot;:&quot;lat&quot;,&quot;id&quot;:&quot;traffic_station&quot;}) While this approach allowed Emma to stay in her beloved Python and avoid costly conversions, the PyKX object API offered other alternatives to query q tables that were worth exploring. Firstly, she had heard that kdb supported querying through plain-old ANSI SQL, and this possibility was enabled through PyKX as well! This time, she decided to use the weather dataset to test this feature: &gt;&gt;&gt; weather = kx.q.read.csv(&#39;./abr_meteo23.csv&#39;, types=&#39;IIII****&#39; + &#39;FS&#39;*24, delimiter=&#39;;&#39;, as_table=True) Once loaded, she issued a simple SQL query: &gt;&gt;&gt; kx.q.sql(&#39;select STATION, count(distinct(MAGNITUDE)) from $1 group by STATION&#39;, weather) pykx.Table(pykx.q(&#39; STATION MAGNITUDE ------------------ 4 1 8 2 16 2 ... That was nice, but she had also heard about qSQL, a collection of query templates resembling SQL, with enhanced expressiveness when dealing with ordered data. qSQL was also available through PyKX by means of a Pythonic interface: &gt;&gt;&gt; kx.q.qsql.select(weather, columns = {&#39;MAGNITUDE&#39;: &#39;count distinct MAGNITUDE&#39;}, by=[&quot;STATION&quot;]) pykx.KeyedTable(pykx.q(&#39; STATION | MAGNITUDE --------| -------- 4 | 1 8 | 2 16 | 2 ... The pythonic interface proved quite convenient, and it was actually extended to many functions from the q reference card. However, she noticed the absence of equivalent attributes for operators like cast, drop, and exec, among others. So, she needed to explore alternative methods to be able to express arbitrary q expressions. Yet it proved remarkably straightforward! For instance, the previous qSQL query may also be implemented as follows: &gt;&gt;&gt; kx.q(&quot;{select count distinct MAGNITUDE by STATION from x}&quot;, weather) pykx.KeyedTable(pykx.q(&#39; ESTACION| MAGNITUD --------| -------- 4 | 1 8 | 2 16 | 2 ... As an experienced programmer, she was well aware that using strings to represent expressions might not be the most optimal approach. It could lead to errors, vulnerabilities, and a lack of support from the IDE. So, she would recommend to her teams the Pythonic style of the Pandas, SQL and qSQL APIs whenever possible. Chapter 3: Putting the World Upside Down Eventually, Emma’s growing appreciation for and excitement in learning about the q/kdb language encouraged her to increasingly try to adopt it directly. However, her colleagues and new hires all knew – and loved – Python as did she, and her codebase contained many useful reusable Python functions. Fortunately, it was straightforward to execute and eval Python code from within her q session. Emma started to think of PyKX as a gift specially made for her by the Three Wise Men. It truly offered the best of both worlds, the flexibility and familiarity of Python and the sheer power and efficiency of q/kdb. She made her first attempt using a custom-made Python function called cdist, which she had no immediate need to migrate away from Python. From her q console, she typed the expected commands to import the necessary libraries: q) system&quot;l pykx.q&quot;; q) .pykx.pyexec&quot;import numpy as np&quot;; q) .pykx.pyexec&quot;from scipy.spatial.distance import cdist&quot;; The function cdist required several arguments, and Emma simply created new Python variables that referenced q native tables a and b: .pykx.set[`xa1;a[`longitude]]; .pykx.set[`xa2;a[`latitude]]; .pykx.set[`yb1;b[`LONGITUDE]]; .pykx.set[`yb2;b[`LATITUDE]]; Calling the function now simply involved evaluating the corresponding Python code and converting the resulting data back to q (using the backtick `): distance_matrix:flip(.pykx.eval&quot;cdist(np.dstack((yb1,yb2))[0], np.dstack((xa1,xa2))[0])&quot;)`; Alongside her own Python codebase, Mad Flow leveraged highly valuable and popular libraries from the Python ecosystem, such as sci-kit learn (sklearn) for statistical and machine learning. “Perhaps the q ecosystem also offers similar ML libraries?” she rightly thought. However, her teams familiarity with – and trust in - sklearn was irresistible, so they simply wanted to reuse their existing Python scripts, like the following, without modifications: from sklearn.linear_model import LinearRegression def model(table): X = table[[&quot;address&quot;, &quot;humidity&quot;, &quot;precipitation&quot;, &quot;pressure&quot;, &quot;solar&quot;, &quot;temperature&quot;, &quot;wind&quot; ]].to_numpy() y = table[&quot;load&quot;].to_numpy().ravel() reg = LinearRegression().fit(X, y) return reg.score(X, y) This time, though, she took a different approach to invoke the model function. She retrieved it into a PyKX object within the q space using pykx.get and utilized the PyKX function-call interface: modelfunc:.pykx.get`model; res:modelfunc[data]; print res`; Conclusions As a CTO managing a talented yet pressured team, Emma was particularly aware of the trade-offs that introducing new technologies posed to Mad Flow. On one hand, state-of-the-art technologies promise enormous performance, efficiency, and infrastructure cost reductions. On the other hand, team culture and the overwhelming comfort and appreciation of community tools, such as Python, could hinder these advantages if technologists just want to stick with their preferred tools. Emma therefore especially appreciated PyKX as a vehicle to bring production capabilities into a Python-friendly organization, and those who influenced the codebase from the Python community at large. Her teams couldn’t have been happier with the result. They could maintain and enhance their programming environment of choice, but swiftly transition onerous tasks to q/kdb. Thus PyKX allowed Emma to avoid the “with me or against me” mentality that comes with change. There was no unpopular abandonment of Python, far from it. Instead Python took on new meaning as it became the vehicle to steer more analytics into production and make those already in production much more perform. In fact, she soon appointed three of their top architects, Félix, Jesús, and Eloy, as team leads for three different teams responsible for various roles within the Mad Flow ecosystem utilizing the new infrastructure. These appointments align with the three different use cases for the PyKX library described in this post. Stay tuned for the follow-up to this post, where Félix, Jesús, and Eloy will elaborate on the use case of heavy traffic and the utilization of PyKX! Acknowledgments This post was greatly enhanced thanks to the edits and comments from Steve Wilcokson and Conor McCarthy from KX. Óscar Nydza, Juan M. Serrano, and Marcos Vázquez from Habla Computing did their best to finalize the draft left by Jesús before he started to enjoy his paternity leave to take care of Félix, Jesús, and Eloy. Dedication This post is dedicated to Eloy and the three newborns at Habla: Emma, Félix, and Jesús. Post Picture: Project for “Destino”, Salvador Dalí (1946)" />
<meta property="og:description" content="All Roads Lead to Kdb: A Python to Production tale Introducing Emma Monad, the main character of our story and CTO of Mad Flow, a large and fictional company dedicated to improving the quality of life in Madrid. Emma was facing the real-world challenge of tackling the issue of heavy traffic in the city. However, she found herself grappling with an outdated, ad-hoc constructed, somewhat inflexible, Mad Flow infrastructure stack. It was a code base that incorporated various modules developed over time, by in-house data science, engineering and developer teams with the help of occasional interns from the nearby university. The application was predominantly built in Python, the most popular programming language of data science over the last decade. However, there were problems with the infrastructure. While open and customizable, it suffered with chaotic organization and frequent performance issues, meaning it was slow and unwieldy when incorporating new traffic data-sets or building new insights quickly. This combined to hinder their ability to define and progress effective transport solutions for the city. Emma wanted to take the greatness of the Mad Flow code base, unlock its true potential, and help fulfil its and their mission of transforming Madrid into a more pleasant, efficient and environmentally friendly city. Emma thus wanted more agile data management and effective production-ready analytics easily deployed. She had heard, via some occasional consultants to her organization, about a popular and seemingly blindingly fast time-series database and analytics platform called kdb. Nevertheless, that was not for her she felt. Her team’s comfort was in Python, the language that Mad Flow was predominantly written in, and it was simply impractical to build in anything else, so Python it was. However, at a local PyData Meetup Emma attended, a data scientist acquaintance told her over drinks about PyKX, an open-source library allowing Python to remain the guiding language, but harnessing the power of kdb at runtime. She decided to give it a try, and as time proved, PyKX just worked, and was indispensable in guiding the team from taking a predominantly ad-hoc research data and analytics codebase into a production powerhouse. The rest of this story tells you how and why. Chapter 1: I just want to stay in Python Setting up kdb to ingest the traffic data, Emma feared, might require several weeks. Somewhat apprehensively, Emma set expectations with her team accordingly. However, there she was, with a skilled Python team that had no prior experience in writing even a simple “Hello World” in Q (which, by the way, is 0N!”Hello World!”), and a Python REPL waiting for instructions. She tried to conceal her fear, and she typed the very first line of PyKX code in the Python shell: &gt;&gt;&gt; import pykx as kx A sense of calm washed over her as she saw that everything was going well. Madrid has many traffic devices scattered throughout the city, so her first task was to retrieve their information, available in several .csv files, into the new platform. According to the PyKX documentation, the pykx.read attribute seemed to be her best option: tdevices = kx.q.read.csv(&quot;devices.csv&quot;, types = &quot;JFFJJSSS&quot;, delimiter=&quot;;&quot;, as_table=True) Her team had extensive familiarity with Pandas notation, so she decided to try some Pandas instructions to retrieve a few columns from the table. It worked effortlessly, or at least it seemed so at first. &gt;&gt;&gt; tdevices[[&#39;district&#39;, &#39;id&#39;, &#39;latitude&#39;, &#39;longitude&#39;]] pykx.List(pykx.q(&#39; 4 4 1 4 4 4 1 7 .. 3840 3841 3842 3843 3844 3845 3846 3847 .. 40.4305 40.43052 40.42213 40.42143 40.43378 40.42351 40.42816 40.42879.. -3.688323 -3.687256 -3.691727 -3.691929 -3.68847 -3.690991 -3.698403 -3.69455.. &#39;)) “Yikes!” It was so close, but it didn’t look like a dataframe. “Where are my columns?” she thought. That wouldn’t impress her colleagues, for whom familiar columns mattered. If this was to be a barrier, then it would likely be even harder to run the required analytics algorithms on the proposed new platform. But the documentation suggested the pdcommand which just worked: &gt;&gt;&gt; tdevices.pd()[[&#39;district&#39;, &#39;id&#39;, &#39;longitude&#39;, &#39;latitude&#39;]] district id longitude latitude 0 4 3840 -3.688323 40.430502 1 4 3841 -3.687256 40.430524 2 1 3842 -3.691727 40.422132 ... ... ... ... ... 4741 16 6933 -3.672497 40.484118 4742 16 7129 -3.672500 40.484181 4743 16 7015 -3.672308 40.485002 [4744 rows x 4 columns] Et voilà! Emma simply had to repeat the process to load the remaining dataframes used by the selected algorithm, and she could execute the program smoothly, in its very original form. She had intentionally choose an algorithm that produced output in the form of familiar CSV file standards because that was what she and her team knew, but her PyData and kdb-knowledgeable fellow attendee had told her that kdb data stores were so much more efficient. For now, though, she’d stay with csv. Nonetheless, this marked a significant milestone. Emma had already felt that some of the initial promises were delivered! However, she was well aware of the long road ahead of her if she was to bring along her team and make Mad Flow the agile production analytics platform she wanted it to be. Chapter 2: From Zero to Hero Several weeks passed, and, having onboarded a couple of data scientist interns, she finally found time to work with them and conduct more research on PyKX. “Do as little work as necessary,” she murmured. “I just want my team to work with what they’re comfortable with, but have kdb do the heavy lifting!” Emma repeated these mantras from the PyKX user guide to herself whenever she was tempted to use pd. Indeed, she was now well aware that in order to fully harness the platform’s potential, she should minimize data transfers between the two realms, and delegate as much work as possible to the kdb infrastructure. The key to achieving these goals lay in leveraging the PyKX object API, which allowed a Python-first approach. This API made it easy to embed q/kdb within Python, enabling the direct use of efficient q functions in Python code. Additionally, it provided convenient re-implementations of Pythonic APIs, like the Pandas APIs, eliminating the need for conversions to Pandas in many cases. If feasible, this would enhance the development experience, reduce the chances of errors, and, the team hoped, significantly improve performance. She first tried with the PyKX Pandas API re-implementation, which could be actrivated through the following environment variable: &gt;&gt;&gt; import os &gt;&gt;&gt; os.environ[&#39;PYKX_ENABLE_PANDAS_API&#39;] = &#39;true&#39; Then, she tried the exact same Pandas expression as in the previous section: &gt;&gt;&gt; tdevices[[&#39;district&#39;, &#39;id&#39;, &#39;latitude&#39;, &#39;longitude&#39;]] pykx.Table(pykx.q(&#39; district id latitude longitude -------------------------------- 4 3840 40.4305 -3.688323 4 3841 40.43052 -3.687256 1 3842 40.42213 -3.691727 4 3843 40.42143 -3.691929 4 3844 40.43378 -3.68847 ... &#39;)) Et voilà! There were the columns, and she didn’t need to convert q tables to Pandas dataframes! “Do as little work as necessary?” Nailed it! And this approach worked for many other methods of the Pandas API as well, such as filtering, dropping, and renaming columns. &gt;&gt;&gt; tdevices = tdevices[tdevices[&quot;elem_type&quot;] == &quot;URB&quot;] &gt;&gt;&gt; tdevices = tdevices.drop([&quot;elem_type&quot;,&quot;district&quot;, &quot;cod_cent&quot;, &quot;name&quot;, &quot;utm_x&quot;, &quot;utm_y&quot;], axis=1) &gt;&gt;&gt; tdevices = tdevices.rename(columns={&quot;longitude&quot;:&quot;long&quot;, &quot;latitude&quot;:&quot;lat&quot;,&quot;id&quot;:&quot;traffic_station&quot;}) While this approach allowed Emma to stay in her beloved Python and avoid costly conversions, the PyKX object API offered other alternatives to query q tables that were worth exploring. Firstly, she had heard that kdb supported querying through plain-old ANSI SQL, and this possibility was enabled through PyKX as well! This time, she decided to use the weather dataset to test this feature: &gt;&gt;&gt; weather = kx.q.read.csv(&#39;./abr_meteo23.csv&#39;, types=&#39;IIII****&#39; + &#39;FS&#39;*24, delimiter=&#39;;&#39;, as_table=True) Once loaded, she issued a simple SQL query: &gt;&gt;&gt; kx.q.sql(&#39;select STATION, count(distinct(MAGNITUDE)) from $1 group by STATION&#39;, weather) pykx.Table(pykx.q(&#39; STATION MAGNITUDE ------------------ 4 1 8 2 16 2 ... That was nice, but she had also heard about qSQL, a collection of query templates resembling SQL, with enhanced expressiveness when dealing with ordered data. qSQL was also available through PyKX by means of a Pythonic interface: &gt;&gt;&gt; kx.q.qsql.select(weather, columns = {&#39;MAGNITUDE&#39;: &#39;count distinct MAGNITUDE&#39;}, by=[&quot;STATION&quot;]) pykx.KeyedTable(pykx.q(&#39; STATION | MAGNITUDE --------| -------- 4 | 1 8 | 2 16 | 2 ... The pythonic interface proved quite convenient, and it was actually extended to many functions from the q reference card. However, she noticed the absence of equivalent attributes for operators like cast, drop, and exec, among others. So, she needed to explore alternative methods to be able to express arbitrary q expressions. Yet it proved remarkably straightforward! For instance, the previous qSQL query may also be implemented as follows: &gt;&gt;&gt; kx.q(&quot;{select count distinct MAGNITUDE by STATION from x}&quot;, weather) pykx.KeyedTable(pykx.q(&#39; ESTACION| MAGNITUD --------| -------- 4 | 1 8 | 2 16 | 2 ... As an experienced programmer, she was well aware that using strings to represent expressions might not be the most optimal approach. It could lead to errors, vulnerabilities, and a lack of support from the IDE. So, she would recommend to her teams the Pythonic style of the Pandas, SQL and qSQL APIs whenever possible. Chapter 3: Putting the World Upside Down Eventually, Emma’s growing appreciation for and excitement in learning about the q/kdb language encouraged her to increasingly try to adopt it directly. However, her colleagues and new hires all knew – and loved – Python as did she, and her codebase contained many useful reusable Python functions. Fortunately, it was straightforward to execute and eval Python code from within her q session. Emma started to think of PyKX as a gift specially made for her by the Three Wise Men. It truly offered the best of both worlds, the flexibility and familiarity of Python and the sheer power and efficiency of q/kdb. She made her first attempt using a custom-made Python function called cdist, which she had no immediate need to migrate away from Python. From her q console, she typed the expected commands to import the necessary libraries: q) system&quot;l pykx.q&quot;; q) .pykx.pyexec&quot;import numpy as np&quot;; q) .pykx.pyexec&quot;from scipy.spatial.distance import cdist&quot;; The function cdist required several arguments, and Emma simply created new Python variables that referenced q native tables a and b: .pykx.set[`xa1;a[`longitude]]; .pykx.set[`xa2;a[`latitude]]; .pykx.set[`yb1;b[`LONGITUDE]]; .pykx.set[`yb2;b[`LATITUDE]]; Calling the function now simply involved evaluating the corresponding Python code and converting the resulting data back to q (using the backtick `): distance_matrix:flip(.pykx.eval&quot;cdist(np.dstack((yb1,yb2))[0], np.dstack((xa1,xa2))[0])&quot;)`; Alongside her own Python codebase, Mad Flow leveraged highly valuable and popular libraries from the Python ecosystem, such as sci-kit learn (sklearn) for statistical and machine learning. “Perhaps the q ecosystem also offers similar ML libraries?” she rightly thought. However, her teams familiarity with – and trust in - sklearn was irresistible, so they simply wanted to reuse their existing Python scripts, like the following, without modifications: from sklearn.linear_model import LinearRegression def model(table): X = table[[&quot;address&quot;, &quot;humidity&quot;, &quot;precipitation&quot;, &quot;pressure&quot;, &quot;solar&quot;, &quot;temperature&quot;, &quot;wind&quot; ]].to_numpy() y = table[&quot;load&quot;].to_numpy().ravel() reg = LinearRegression().fit(X, y) return reg.score(X, y) This time, though, she took a different approach to invoke the model function. She retrieved it into a PyKX object within the q space using pykx.get and utilized the PyKX function-call interface: modelfunc:.pykx.get`model; res:modelfunc[data]; print res`; Conclusions As a CTO managing a talented yet pressured team, Emma was particularly aware of the trade-offs that introducing new technologies posed to Mad Flow. On one hand, state-of-the-art technologies promise enormous performance, efficiency, and infrastructure cost reductions. On the other hand, team culture and the overwhelming comfort and appreciation of community tools, such as Python, could hinder these advantages if technologists just want to stick with their preferred tools. Emma therefore especially appreciated PyKX as a vehicle to bring production capabilities into a Python-friendly organization, and those who influenced the codebase from the Python community at large. Her teams couldn’t have been happier with the result. They could maintain and enhance their programming environment of choice, but swiftly transition onerous tasks to q/kdb. Thus PyKX allowed Emma to avoid the “with me or against me” mentality that comes with change. There was no unpopular abandonment of Python, far from it. Instead Python took on new meaning as it became the vehicle to steer more analytics into production and make those already in production much more perform. In fact, she soon appointed three of their top architects, Félix, Jesús, and Eloy, as team leads for three different teams responsible for various roles within the Mad Flow ecosystem utilizing the new infrastructure. These appointments align with the three different use cases for the PyKX library described in this post. Stay tuned for the follow-up to this post, where Félix, Jesús, and Eloy will elaborate on the use case of heavy traffic and the utilization of PyKX! Acknowledgments This post was greatly enhanced thanks to the edits and comments from Steve Wilcokson and Conor McCarthy from KX. Óscar Nydza, Juan M. Serrano, and Marcos Vázquez from Habla Computing did their best to finalize the draft left by Jesús before he started to enjoy his paternity leave to take care of Félix, Jesús, and Eloy. Dedication This post is dedicated to Eloy and the three newborns at Habla: Emma, Félix, and Jesús. Post Picture: Project for “Destino”, Salvador Dalí (1946)" />
<link rel="canonical" href="http://localhost:4000/2023/07/31/all-roads-lead-to-pykx.html" />
<meta property="og:url" content="http://localhost:4000/2023/07/31/all-roads-lead-to-pykx.html" />
<meta property="og:site_name" content="Habla computing Blog" />
<meta property="og:image" content="http://localhost:4000/img/destino.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-07-31T00:00:00+02:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="http://localhost:4000/img/destino.jpg" />
<meta property="twitter:title" content="All roads lead to PyKX" />
<script type="application/ld+json">
{"@type":"BlogPosting","image":"http://localhost:4000/img/destino.jpg","headline":"All roads lead to PyKX","dateModified":"2023-07-31T00:00:00+02:00","datePublished":"2023-07-31T00:00:00+02:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2023/07/31/all-roads-lead-to-pykx.html"},"author":{"@type":"Person","name":"Jesús López-González"},"description":"All Roads Lead to Kdb: A Python to Production tale Introducing Emma Monad, the main character of our story and CTO of Mad Flow, a large and fictional company dedicated to improving the quality of life in Madrid. Emma was facing the real-world challenge of tackling the issue of heavy traffic in the city. However, she found herself grappling with an outdated, ad-hoc constructed, somewhat inflexible, Mad Flow infrastructure stack. It was a code base that incorporated various modules developed over time, by in-house data science, engineering and developer teams with the help of occasional interns from the nearby university. The application was predominantly built in Python, the most popular programming language of data science over the last decade. However, there were problems with the infrastructure. While open and customizable, it suffered with chaotic organization and frequent performance issues, meaning it was slow and unwieldy when incorporating new traffic data-sets or building new insights quickly. This combined to hinder their ability to define and progress effective transport solutions for the city. Emma wanted to take the greatness of the Mad Flow code base, unlock its true potential, and help fulfil its and their mission of transforming Madrid into a more pleasant, efficient and environmentally friendly city. Emma thus wanted more agile data management and effective production-ready analytics easily deployed. She had heard, via some occasional consultants to her organization, about a popular and seemingly blindingly fast time-series database and analytics platform called kdb. Nevertheless, that was not for her she felt. Her team’s comfort was in Python, the language that Mad Flow was predominantly written in, and it was simply impractical to build in anything else, so Python it was. However, at a local PyData Meetup Emma attended, a data scientist acquaintance told her over drinks about PyKX, an open-source library allowing Python to remain the guiding language, but harnessing the power of kdb at runtime. She decided to give it a try, and as time proved, PyKX just worked, and was indispensable in guiding the team from taking a predominantly ad-hoc research data and analytics codebase into a production powerhouse. The rest of this story tells you how and why. Chapter 1: I just want to stay in Python Setting up kdb to ingest the traffic data, Emma feared, might require several weeks. Somewhat apprehensively, Emma set expectations with her team accordingly. However, there she was, with a skilled Python team that had no prior experience in writing even a simple “Hello World” in Q (which, by the way, is 0N!”Hello World!”), and a Python REPL waiting for instructions. She tried to conceal her fear, and she typed the very first line of PyKX code in the Python shell: &gt;&gt;&gt; import pykx as kx A sense of calm washed over her as she saw that everything was going well. Madrid has many traffic devices scattered throughout the city, so her first task was to retrieve their information, available in several .csv files, into the new platform. According to the PyKX documentation, the pykx.read attribute seemed to be her best option: tdevices = kx.q.read.csv(&quot;devices.csv&quot;, types = &quot;JFFJJSSS&quot;, delimiter=&quot;;&quot;, as_table=True) Her team had extensive familiarity with Pandas notation, so she decided to try some Pandas instructions to retrieve a few columns from the table. It worked effortlessly, or at least it seemed so at first. &gt;&gt;&gt; tdevices[[&#39;district&#39;, &#39;id&#39;, &#39;latitude&#39;, &#39;longitude&#39;]] pykx.List(pykx.q(&#39; 4 4 1 4 4 4 1 7 .. 3840 3841 3842 3843 3844 3845 3846 3847 .. 40.4305 40.43052 40.42213 40.42143 40.43378 40.42351 40.42816 40.42879.. -3.688323 -3.687256 -3.691727 -3.691929 -3.68847 -3.690991 -3.698403 -3.69455.. &#39;)) “Yikes!” It was so close, but it didn’t look like a dataframe. “Where are my columns?” she thought. That wouldn’t impress her colleagues, for whom familiar columns mattered. If this was to be a barrier, then it would likely be even harder to run the required analytics algorithms on the proposed new platform. But the documentation suggested the pdcommand which just worked: &gt;&gt;&gt; tdevices.pd()[[&#39;district&#39;, &#39;id&#39;, &#39;longitude&#39;, &#39;latitude&#39;]] district id longitude latitude 0 4 3840 -3.688323 40.430502 1 4 3841 -3.687256 40.430524 2 1 3842 -3.691727 40.422132 ... ... ... ... ... 4741 16 6933 -3.672497 40.484118 4742 16 7129 -3.672500 40.484181 4743 16 7015 -3.672308 40.485002 [4744 rows x 4 columns] Et voilà! Emma simply had to repeat the process to load the remaining dataframes used by the selected algorithm, and she could execute the program smoothly, in its very original form. She had intentionally choose an algorithm that produced output in the form of familiar CSV file standards because that was what she and her team knew, but her PyData and kdb-knowledgeable fellow attendee had told her that kdb data stores were so much more efficient. For now, though, she’d stay with csv. Nonetheless, this marked a significant milestone. Emma had already felt that some of the initial promises were delivered! However, she was well aware of the long road ahead of her if she was to bring along her team and make Mad Flow the agile production analytics platform she wanted it to be. Chapter 2: From Zero to Hero Several weeks passed, and, having onboarded a couple of data scientist interns, she finally found time to work with them and conduct more research on PyKX. “Do as little work as necessary,” she murmured. “I just want my team to work with what they’re comfortable with, but have kdb do the heavy lifting!” Emma repeated these mantras from the PyKX user guide to herself whenever she was tempted to use pd. Indeed, she was now well aware that in order to fully harness the platform’s potential, she should minimize data transfers between the two realms, and delegate as much work as possible to the kdb infrastructure. The key to achieving these goals lay in leveraging the PyKX object API, which allowed a Python-first approach. This API made it easy to embed q/kdb within Python, enabling the direct use of efficient q functions in Python code. Additionally, it provided convenient re-implementations of Pythonic APIs, like the Pandas APIs, eliminating the need for conversions to Pandas in many cases. If feasible, this would enhance the development experience, reduce the chances of errors, and, the team hoped, significantly improve performance. She first tried with the PyKX Pandas API re-implementation, which could be actrivated through the following environment variable: &gt;&gt;&gt; import os &gt;&gt;&gt; os.environ[&#39;PYKX_ENABLE_PANDAS_API&#39;] = &#39;true&#39; Then, she tried the exact same Pandas expression as in the previous section: &gt;&gt;&gt; tdevices[[&#39;district&#39;, &#39;id&#39;, &#39;latitude&#39;, &#39;longitude&#39;]] pykx.Table(pykx.q(&#39; district id latitude longitude -------------------------------- 4 3840 40.4305 -3.688323 4 3841 40.43052 -3.687256 1 3842 40.42213 -3.691727 4 3843 40.42143 -3.691929 4 3844 40.43378 -3.68847 ... &#39;)) Et voilà! There were the columns, and she didn’t need to convert q tables to Pandas dataframes! “Do as little work as necessary?” Nailed it! And this approach worked for many other methods of the Pandas API as well, such as filtering, dropping, and renaming columns. &gt;&gt;&gt; tdevices = tdevices[tdevices[&quot;elem_type&quot;] == &quot;URB&quot;] &gt;&gt;&gt; tdevices = tdevices.drop([&quot;elem_type&quot;,&quot;district&quot;, &quot;cod_cent&quot;, &quot;name&quot;, &quot;utm_x&quot;, &quot;utm_y&quot;], axis=1) &gt;&gt;&gt; tdevices = tdevices.rename(columns={&quot;longitude&quot;:&quot;long&quot;, &quot;latitude&quot;:&quot;lat&quot;,&quot;id&quot;:&quot;traffic_station&quot;}) While this approach allowed Emma to stay in her beloved Python and avoid costly conversions, the PyKX object API offered other alternatives to query q tables that were worth exploring. Firstly, she had heard that kdb supported querying through plain-old ANSI SQL, and this possibility was enabled through PyKX as well! This time, she decided to use the weather dataset to test this feature: &gt;&gt;&gt; weather = kx.q.read.csv(&#39;./abr_meteo23.csv&#39;, types=&#39;IIII****&#39; + &#39;FS&#39;*24, delimiter=&#39;;&#39;, as_table=True) Once loaded, she issued a simple SQL query: &gt;&gt;&gt; kx.q.sql(&#39;select STATION, count(distinct(MAGNITUDE)) from $1 group by STATION&#39;, weather) pykx.Table(pykx.q(&#39; STATION MAGNITUDE ------------------ 4 1 8 2 16 2 ... That was nice, but she had also heard about qSQL, a collection of query templates resembling SQL, with enhanced expressiveness when dealing with ordered data. qSQL was also available through PyKX by means of a Pythonic interface: &gt;&gt;&gt; kx.q.qsql.select(weather, columns = {&#39;MAGNITUDE&#39;: &#39;count distinct MAGNITUDE&#39;}, by=[&quot;STATION&quot;]) pykx.KeyedTable(pykx.q(&#39; STATION | MAGNITUDE --------| -------- 4 | 1 8 | 2 16 | 2 ... The pythonic interface proved quite convenient, and it was actually extended to many functions from the q reference card. However, she noticed the absence of equivalent attributes for operators like cast, drop, and exec, among others. So, she needed to explore alternative methods to be able to express arbitrary q expressions. Yet it proved remarkably straightforward! For instance, the previous qSQL query may also be implemented as follows: &gt;&gt;&gt; kx.q(&quot;{select count distinct MAGNITUDE by STATION from x}&quot;, weather) pykx.KeyedTable(pykx.q(&#39; ESTACION| MAGNITUD --------| -------- 4 | 1 8 | 2 16 | 2 ... As an experienced programmer, she was well aware that using strings to represent expressions might not be the most optimal approach. It could lead to errors, vulnerabilities, and a lack of support from the IDE. So, she would recommend to her teams the Pythonic style of the Pandas, SQL and qSQL APIs whenever possible. Chapter 3: Putting the World Upside Down Eventually, Emma’s growing appreciation for and excitement in learning about the q/kdb language encouraged her to increasingly try to adopt it directly. However, her colleagues and new hires all knew – and loved – Python as did she, and her codebase contained many useful reusable Python functions. Fortunately, it was straightforward to execute and eval Python code from within her q session. Emma started to think of PyKX as a gift specially made for her by the Three Wise Men. It truly offered the best of both worlds, the flexibility and familiarity of Python and the sheer power and efficiency of q/kdb. She made her first attempt using a custom-made Python function called cdist, which she had no immediate need to migrate away from Python. From her q console, she typed the expected commands to import the necessary libraries: q) system&quot;l pykx.q&quot;; q) .pykx.pyexec&quot;import numpy as np&quot;; q) .pykx.pyexec&quot;from scipy.spatial.distance import cdist&quot;; The function cdist required several arguments, and Emma simply created new Python variables that referenced q native tables a and b: .pykx.set[`xa1;a[`longitude]]; .pykx.set[`xa2;a[`latitude]]; .pykx.set[`yb1;b[`LONGITUDE]]; .pykx.set[`yb2;b[`LATITUDE]]; Calling the function now simply involved evaluating the corresponding Python code and converting the resulting data back to q (using the backtick `): distance_matrix:flip(.pykx.eval&quot;cdist(np.dstack((yb1,yb2))[0], np.dstack((xa1,xa2))[0])&quot;)`; Alongside her own Python codebase, Mad Flow leveraged highly valuable and popular libraries from the Python ecosystem, such as sci-kit learn (sklearn) for statistical and machine learning. “Perhaps the q ecosystem also offers similar ML libraries?” she rightly thought. However, her teams familiarity with – and trust in - sklearn was irresistible, so they simply wanted to reuse their existing Python scripts, like the following, without modifications: from sklearn.linear_model import LinearRegression def model(table): X = table[[&quot;address&quot;, &quot;humidity&quot;, &quot;precipitation&quot;, &quot;pressure&quot;, &quot;solar&quot;, &quot;temperature&quot;, &quot;wind&quot; ]].to_numpy() y = table[&quot;load&quot;].to_numpy().ravel() reg = LinearRegression().fit(X, y) return reg.score(X, y) This time, though, she took a different approach to invoke the model function. She retrieved it into a PyKX object within the q space using pykx.get and utilized the PyKX function-call interface: modelfunc:.pykx.get`model; res:modelfunc[data]; print res`; Conclusions As a CTO managing a talented yet pressured team, Emma was particularly aware of the trade-offs that introducing new technologies posed to Mad Flow. On one hand, state-of-the-art technologies promise enormous performance, efficiency, and infrastructure cost reductions. On the other hand, team culture and the overwhelming comfort and appreciation of community tools, such as Python, could hinder these advantages if technologists just want to stick with their preferred tools. Emma therefore especially appreciated PyKX as a vehicle to bring production capabilities into a Python-friendly organization, and those who influenced the codebase from the Python community at large. Her teams couldn’t have been happier with the result. They could maintain and enhance their programming environment of choice, but swiftly transition onerous tasks to q/kdb. Thus PyKX allowed Emma to avoid the “with me or against me” mentality that comes with change. There was no unpopular abandonment of Python, far from it. Instead Python took on new meaning as it became the vehicle to steer more analytics into production and make those already in production much more perform. In fact, she soon appointed three of their top architects, Félix, Jesús, and Eloy, as team leads for three different teams responsible for various roles within the Mad Flow ecosystem utilizing the new infrastructure. These appointments align with the three different use cases for the PyKX library described in this post. Stay tuned for the follow-up to this post, where Félix, Jesús, and Eloy will elaborate on the use case of heavy traffic and the utilization of PyKX! Acknowledgments This post was greatly enhanced thanks to the edits and comments from Steve Wilcokson and Conor McCarthy from KX. Óscar Nydza, Juan M. Serrano, and Marcos Vázquez from Habla Computing did their best to finalize the draft left by Jesús before he started to enjoy his paternity leave to take care of Félix, Jesús, and Eloy. Dedication This post is dedicated to Eloy and the three newborns at Habla: Emma, Félix, and Jesús. Post Picture: Project for “Destino”, Salvador Dalí (1946)","url":"http://localhost:4000/2023/07/31/all-roads-lead-to-pykx.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-140060849-1"></script>
<script>
  window['ga-disable-UA-140060849-1'] = window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1";
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-140060849-1');
</script></head>

<body>
<div class="navbar is-white">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item" href="/">
                Habla computing Blog
            </a>
            <a role="button" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navMenu">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu" id="navMenu">
            <div class="navbar-end">
                
                <a class="navbar-item" href="/authors/">Authors</a>
                
            </div>
        </div>
    </div>
</div>

    <section class="hero  is-medium  is-bold is-dark"  style="background: url('/img/destino.jpg') no-repeat center center; background-size: cover;" >
    <div class="hero-body">
        <div class="container">
            <p class="title is-2">All roads lead to PyKX</p>
            <p class="subtitle is-3"></p>
        </div>
    </div>
</section>

<section class="section">
    <div class="container">
        

<div class="columns is-centered">
    <div class="column is-8-desktop is-10-tablet">
        <div class="content">
            <p><strong>Published: Jul 31, 2023 by Jesús López-González</strong></p>
            <h1 id="all-roads-lead-to-kdb-a-python-to-production-tale">All Roads Lead to Kdb: A Python to Production tale</h1>

<p>Introducing Emma Monad, the main character of our story and CTO of Mad Flow, a large and fictional company dedicated to improving the quality of life in Madrid. Emma was facing the real-world challenge of tackling the issue of heavy traffic in the city. However, she found herself grappling with an outdated, ad-hoc constructed, somewhat
inflexible, Mad Flow infrastructure stack. It was a code base that incorporated various modules developed over time, by in-house data science, engineering and developer teams with the help of occasional interns from the nearby university. The application was predominantly built in Python, the most popular programming language of data science over the last decade.</p>

<p>However, there were problems with the infrastructure. While open and customizable, it suffered with chaotic organization and frequent performance issues, meaning it was slow and unwieldy when incorporating new traffic data-sets or building new insights quickly. This combined to hinder their ability to define and progress effective transport solutions for the city. Emma wanted to take the greatness of the Mad Flow code base, unlock its true potential, and help fulfil its and their mission of transforming Madrid into a more pleasant, efficient and environmentally friendly city.</p>

<p>Emma thus wanted more agile data management and effective production-ready analytics easily deployed. She had heard, via some occasional consultants to her organization, about a popular and seemingly blindingly fast time-series database and analytics platform called kdb. Nevertheless, that was not for her she felt. Her team’s
comfort was in Python, the language that Mad Flow was predominantly written in, and it was simply impractical to build in anything else, so Python it was. However, at a local PyData Meetup Emma attended, a data scientist acquaintance told her over drinks about PyKX, an open-source library allowing Python to remain the guiding language, but harnessing the power of kdb at runtime. She decided to give it a try, and as time proved, PyKX just worked, and was indispensable in guiding the team from taking a predominantly ad-hoc research data and analytics codebase into a production powerhouse.</p>

<p>The rest of this story tells you how and why.</p>

<h2 id="chapter-1-i-just-want-to-stay-in-python">Chapter 1: I just want to stay in Python</h2>

<p>Setting up kdb to ingest the traffic data, Emma feared, might require several weeks. Somewhat apprehensively, Emma set expectations with her team accordingly. However, there she was, with a skilled Python team that had no prior experience in writing even a simple “Hello World” in Q (which, by the way, is 0N!”Hello World!”), and a Python REPL waiting for instructions. She tried to conceal her fear, and she typed the very first line of PyKX code in the Python shell:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">pykx</span> <span class="k">as</span> <span class="n">kx</span>
</code></pre></div></div>

<p>A sense of calm washed over her as she saw that everything was going well.</p>

<p>Madrid has many traffic devices scattered throughout the city, so her first task was to retrieve their information, available in several .csv files, into the new platform. According to the PyKX documentation, the  <code class="language-plaintext highlighter-rouge">pykx.read</code> attribute seemed to be her best option:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tdevices</span> <span class="o">=</span> <span class="n">kx</span><span class="p">.</span><span class="n">q</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">csv</span><span class="p">(</span><span class="s">"devices.csv"</span><span class="p">,</span> <span class="n">types</span> <span class="o">=</span> <span class="s">"JFFJJSSS"</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">";"</span><span class="p">,</span> <span class="n">as_table</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>Her team had extensive familiarity with Pandas notation, so she decided to try some Pandas instructions to retrieve a few columns from the table. It worked effortlessly, or at least it seemed so at first.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">tdevices</span><span class="p">[[</span><span class="s">'district'</span><span class="p">,</span> <span class="s">'id'</span><span class="p">,</span> <span class="s">'latitude'</span><span class="p">,</span> <span class="s">'longitude'</span><span class="p">]]</span>
<span class="n">pykx</span><span class="p">.</span><span class="n">List</span><span class="p">(</span><span class="n">pykx</span><span class="p">.</span><span class="n">q</span><span class="p">(</span><span class="s">'
4         4         1         4         4        4         1         7       ..
3840      3841      3842      3843      3844     3845      3846      3847    ..
40.4305   40.43052  40.42213  40.42143  40.43378 40.42351  40.42816  40.42879..
-3.688323 -3.687256 -3.691727 -3.691929 -3.68847 -3.690991 -3.698403 -3.69455..
'</span><span class="p">))</span>
</code></pre></div></div>

<p>“Yikes!” It was so close, but it didn’t look like a dataframe. “Where are my columns?” she thought.</p>

<p>That wouldn’t impress her colleagues, for whom familiar columns mattered. If this was to be a barrier, then it would likely be even harder to run the required analytics algorithms on the proposed new platform. But the documentation suggested the <code class="language-plaintext highlighter-rouge">pd</code>command which just worked:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">tdevices</span><span class="p">.</span><span class="n">pd</span><span class="p">()[[</span><span class="s">'district'</span><span class="p">,</span> <span class="s">'id'</span><span class="p">,</span> <span class="s">'longitude'</span><span class="p">,</span> <span class="s">'latitude'</span><span class="p">]]</span>
      <span class="n">district</span>    <span class="nb">id</span>  <span class="n">longitude</span>   <span class="n">latitude</span>
<span class="mi">0</span>            <span class="mi">4</span>  <span class="mi">3840</span>  <span class="o">-</span><span class="mf">3.688323</span>  <span class="mf">40.430502</span>
<span class="mi">1</span>            <span class="mi">4</span>  <span class="mi">3841</span>  <span class="o">-</span><span class="mf">3.687256</span>  <span class="mf">40.430524</span>
<span class="mi">2</span>            <span class="mi">1</span>  <span class="mi">3842</span>  <span class="o">-</span><span class="mf">3.691727</span>  <span class="mf">40.422132</span>
<span class="p">...</span>        <span class="p">...</span>   <span class="p">...</span>        <span class="p">...</span>        <span class="p">...</span>
<span class="mi">4741</span>        <span class="mi">16</span>  <span class="mi">6933</span>  <span class="o">-</span><span class="mf">3.672497</span>  <span class="mf">40.484118</span>
<span class="mi">4742</span>        <span class="mi">16</span>  <span class="mi">7129</span>  <span class="o">-</span><span class="mf">3.672500</span>  <span class="mf">40.484181</span>
<span class="mi">4743</span>        <span class="mi">16</span>  <span class="mi">7015</span>  <span class="o">-</span><span class="mf">3.672308</span>  <span class="mf">40.485002</span>
<span class="p">[</span><span class="mi">4744</span> <span class="n">rows</span> <span class="n">x</span> <span class="mi">4</span> <span class="n">columns</span><span class="p">]</span>
</code></pre></div></div>

<p>Et voilà! Emma simply had to repeat the process to load the remaining dataframes used by the selected algorithm, and she could execute the program smoothly, in its very original form. She had intentionally choose an algorithm that produced output in the form of familiar CSV file standards because that was what she and her team knew, but her PyData and kdb-knowledgeable fellow attendee had told her that kdb data stores were so much more efficient. For now, though, she’d stay with csv. Nonetheless, this marked a significant milestone. Emma had already felt that some of the initial promises were delivered!  However, she was well aware of the long road ahead of her if she was to bring along her team and make Mad Flow the agile production analytics platform she wanted it to be.</p>

<h2 id="chapter-2-from-zero-to-hero">Chapter 2: From Zero to Hero</h2>

<p>Several weeks passed, and, having onboarded a couple of data scientist interns, she finally found time to work with them and conduct more research on PyKX. “Do as little work as necessary,” she murmured. “I just want my team to work with what they’re comfortable with, but have kdb do the heavy lifting!” Emma repeated these mantras from the PyKX user guide to herself whenever she was tempted to use <code class="language-plaintext highlighter-rouge">pd</code>. Indeed, she was now well aware that in order to fully harness the platform’s potential, she should minimize data transfers between the two realms, and delegate as much work as possible to the kdb infrastructure.</p>

<p>The key to achieving these goals lay in leveraging the PyKX object API, which allowed a Python-first approach. This API made it easy to embed q/kdb within Python, enabling the direct use of efficient q functions in Python code. Additionally, it provided convenient re-implementations of Pythonic APIs, like the Pandas APIs, eliminating the need for conversions to Pandas in many cases. If feasible, this would enhance the development experience, reduce the chances of errors, and, the team hoped, significantly improve performance.</p>

<p>She first tried with the PyKX Pandas API re-implementation, which could be actrivated through the following environment variable:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYKX_ENABLE_PANDAS_API'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'true'</span> 
</code></pre></div></div>

<p>Then, she tried the exact same Pandas expression as in the previous section:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">tdevices</span><span class="p">[[</span><span class="s">'district'</span><span class="p">,</span> <span class="s">'id'</span><span class="p">,</span> <span class="s">'latitude'</span><span class="p">,</span> <span class="s">'longitude'</span><span class="p">]]</span>
<span class="n">pykx</span><span class="p">.</span><span class="n">Table</span><span class="p">(</span><span class="n">pykx</span><span class="p">.</span><span class="n">q</span><span class="p">(</span><span class="s">'
district id   latitude  longitude
--------------------------------
4        3840 40.4305  -3.688323
4        3841 40.43052 -3.687256
1        3842 40.42213 -3.691727
4        3843 40.42143 -3.691929
4        3844 40.43378 -3.68847 
...
'</span><span class="p">))</span>
</code></pre></div></div>

<p>Et voilà! There were the columns, and she didn’t need to convert q tables to Pandas dataframes! “Do as little work as necessary?” Nailed it! And this approach worked for many other methods of the Pandas API as well, such as filtering, dropping, and renaming columns.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">tdevices</span> <span class="o">=</span> <span class="n">tdevices</span><span class="p">[</span><span class="n">tdevices</span><span class="p">[</span><span class="s">"elem_type"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"URB"</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tdevices</span> <span class="o">=</span> <span class="n">tdevices</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">"elem_type"</span><span class="p">,</span><span class="s">"district"</span><span class="p">,</span> <span class="s">"cod_cent"</span><span class="p">,</span> <span class="s">"name"</span><span class="p">,</span> <span class="s">"utm_x"</span><span class="p">,</span> <span class="s">"utm_y"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tdevices</span> <span class="o">=</span> <span class="n">tdevices</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">"longitude"</span><span class="p">:</span><span class="s">"long"</span><span class="p">,</span> <span class="s">"latitude"</span><span class="p">:</span><span class="s">"lat"</span><span class="p">,</span><span class="s">"id"</span><span class="p">:</span><span class="s">"traffic_station"</span><span class="p">})</span>
</code></pre></div></div>

<p>While this approach allowed Emma to stay in her beloved Python and avoid costly conversions, the PyKX object API offered other alternatives to query q tables that were worth exploring. Firstly, she had heard that kdb supported querying through plain-old ANSI SQL, and this possibility was enabled through PyKX as well! This time, she decided to use the <em>weather</em> dataset to test this feature:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">weather</span> <span class="o">=</span> <span class="n">kx</span><span class="p">.</span><span class="n">q</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">csv</span><span class="p">(</span><span class="s">'./abr_meteo23.csv'</span><span class="p">,</span> <span class="n">types</span><span class="o">=</span><span class="s">'IIII****'</span> <span class="o">+</span> <span class="s">'FS'</span><span class="o">*</span><span class="mi">24</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">';'</span><span class="p">,</span> <span class="n">as_table</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>Once loaded, she issued a simple SQL query:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">kx</span><span class="p">.</span><span class="n">q</span><span class="p">.</span><span class="n">sql</span><span class="p">(</span><span class="s">'select STATION, count(distinct(MAGNITUDE)) from $1 group by STATION'</span><span class="p">,</span> <span class="n">weather</span><span class="p">)</span> 
<span class="n">pykx</span><span class="p">.</span><span class="n">Table</span><span class="p">(</span><span class="n">pykx</span><span class="p">.</span><span class="n">q</span><span class="p">(</span><span class="s">'
STATION  MAGNITUDE
------------------
4        1
8        2
16       2
...
</span></code></pre></div></div>

<p>That was nice, but she had also heard about qSQL, a collection of query templates resembling SQL, with enhanced expressiveness when dealing with ordered data. qSQL was also available through PyKX by means of a Pythonic interface:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">kx</span><span class="p">.</span><span class="n">q</span><span class="p">.</span><span class="n">qsql</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">weather</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">{</span><span class="s">'MAGNITUDE'</span><span class="p">:</span> <span class="s">'count distinct MAGNITUDE'</span><span class="p">},</span> <span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s">"STATION"</span><span class="p">])</span>
<span class="n">pykx</span><span class="p">.</span><span class="n">KeyedTable</span><span class="p">(</span><span class="n">pykx</span><span class="p">.</span><span class="n">q</span><span class="p">(</span><span class="s">'
STATION | MAGNITUDE
--------| --------
4       | 1
8       | 2
16      | 2
...
</span></code></pre></div></div>

<p>The pythonic interface proved quite convenient, and it was actually extended to many functions from the <a href="https://code.kx.com/pykx/1.6/api/q/q.html">q reference card</a>. However, she noticed the absence of equivalent attributes for operators like <code class="language-plaintext highlighter-rouge">cast</code>, <code class="language-plaintext highlighter-rouge">drop</code>, and <code class="language-plaintext highlighter-rouge">exec</code>, among others. So, she needed to explore alternative methods to be able to express arbitrary q expressions. Yet it proved remarkably straightforward! For instance, the previous qSQL query may also be implemented as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">kx</span><span class="p">.</span><span class="n">q</span><span class="p">(</span><span class="s">"{select count distinct MAGNITUDE by STATION from x}"</span><span class="p">,</span> <span class="n">weather</span><span class="p">)</span>
<span class="n">pykx</span><span class="p">.</span><span class="n">KeyedTable</span><span class="p">(</span><span class="n">pykx</span><span class="p">.</span><span class="n">q</span><span class="p">(</span><span class="s">'
ESTACION| MAGNITUD
--------| --------
4       | 1
8       | 2
16      | 2
...
</span></code></pre></div></div>

<p>As an experienced programmer, she was well aware that using strings to represent expressions might not be the most optimal approach. It could lead to errors, vulnerabilities, and a lack of support from the IDE. So, she would recommend to her teams the Pythonic style of the Pandas, SQL and qSQL APIs whenever possible.</p>

<h2 id="chapter-3-putting-the-world-upside-down">Chapter 3: Putting the World Upside Down</h2>

<p>Eventually, Emma’s growing appreciation for and excitement in learning about the q/kdb language encouraged her to increasingly try to adopt it directly. However, her colleagues and new hires all knew – and loved – Python as did she, and her codebase contained many useful reusable Python functions. Fortunately, it was straightforward to execute and eval Python code from within her q session.</p>

<p>Emma started to think of PyKX as a gift specially made for her by the Three Wise Men. It truly offered the best of both worlds, the flexibility and familiarity of Python and the sheer power and efficiency of q/kdb.</p>

<p>She made her first attempt using a custom-made Python function called <code class="language-plaintext highlighter-rouge">cdist</code>, which she had no immediate need to migrate away from Python. From her q console, she typed the expected commands to import the necessary libraries:</p>

<div class="language-q highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">q)</span><span class="w"> </span><span class="nb">system</span><span class="s">"l pykx.q"</span><span class="p">;</span>
<span class="kd">q)</span><span class="w"> </span><span class="n">.pykx.pyexec</span><span class="s">"import numpy as np"</span><span class="p">;</span>
<span class="kd">q)</span><span class="w"> </span><span class="n">.pykx.pyexec</span><span class="s">"from scipy.spatial.distance import cdist"</span><span class="p">;</span>
</code></pre></div></div>

<p>The function <code class="language-plaintext highlighter-rouge">cdist</code> required several arguments, and Emma simply created new Python variables that referenced q native tables <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">.</span><span class="n">pykx</span><span class="p">.</span><span class="nb">set</span><span class="p">[</span><span class="sb">`xa1;a[`</span><span class="n">longitude</span><span class="p">]];</span>
<span class="p">.</span><span class="n">pykx</span><span class="p">.</span><span class="nb">set</span><span class="p">[</span><span class="sb">`xa2;a[`</span><span class="n">latitude</span><span class="p">]];</span>
<span class="p">.</span><span class="n">pykx</span><span class="p">.</span><span class="nb">set</span><span class="p">[</span><span class="sb">`yb1;b[`</span><span class="n">LONGITUDE</span><span class="p">]];</span>
<span class="p">.</span><span class="n">pykx</span><span class="p">.</span><span class="nb">set</span><span class="p">[</span><span class="sb">`yb2;b[`</span><span class="n">LATITUDE</span><span class="p">]];</span>
</code></pre></div></div>

<p>Calling the function now simply involved evaluating the corresponding Python code and converting the resulting data back to q (using the backtick `):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">distance_matrix</span><span class="p">:</span><span class="n">flip</span><span class="p">(.</span><span class="n">pykx</span><span class="p">.</span><span class="nb">eval</span><span class="s">"cdist(np.dstack((yb1,yb2))[0], np.dstack((xa1,xa2))[0])"</span><span class="p">)</span><span class="err">`</span><span class="p">;</span>
</code></pre></div></div>

<p>Alongside her own Python codebase, Mad Flow leveraged highly valuable and popular libraries from the Python ecosystem, such as sci-kit learn (<code class="language-plaintext highlighter-rouge">sklearn</code>) for statistical and machine learning. “Perhaps the q ecosystem also offers similar ML libraries?” she rightly thought. However, her teams familiarity with – and trust in - sklearn was irresistible, so they simply wanted to reuse their existing Python scripts, like the following, without modifications:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>


<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">table</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">table</span><span class="p">[[</span><span class="s">"address"</span><span class="p">,</span> <span class="s">"humidity"</span><span class="p">,</span> <span class="s">"precipitation"</span><span class="p">,</span> <span class="s">"pressure"</span><span class="p">,</span> <span class="s">"solar"</span><span class="p">,</span> <span class="s">"temperature"</span><span class="p">,</span> <span class="s">"wind"</span> <span class="p">]].</span><span class="n">to_numpy</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s">"load"</span><span class="p">].</span><span class="n">to_numpy</span><span class="p">().</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">reg</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<p>This time, though, she took a different approach to invoke the <code class="language-plaintext highlighter-rouge">model</code> function. She retrieved it into a PyKX object within the q space using <code class="language-plaintext highlighter-rouge">pykx.get</code> and utilized the PyKX function-call interface:</p>

<div class="language-q highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">modelfunc</span><span class="o">:</span><span class="n">.pykx.get</span><span class="ss">`model</span><span class="p">;</span>
<span class="n">res</span><span class="o">:</span><span class="n">modelfunc</span><span class="p">[</span><span class="n">data</span><span class="p">];</span>
<span class="n">print</span><span class="w"> </span><span class="n">res</span><span class="ss">`</span><span class="p">;</span>
</code></pre></div></div>

<h2 id="conclusions">Conclusions</h2>

<p>As a CTO managing a talented yet pressured team, Emma was particularly aware of the trade-offs that introducing new technologies posed to Mad Flow. On one hand, state-of-the-art technologies promise enormous performance, efficiency, and infrastructure cost reductions. On the other hand, team culture and the overwhelming comfort and appreciation of community tools, such as Python, could hinder these advantages if
technologists just want to stick with their preferred tools. Emma therefore especially appreciated PyKX as a vehicle to bring production capabilities into a Python-friendly organization, and those who influenced the codebase from the Python community at large. Her teams couldn’t have been happier with the result. They could maintain and enhance their programming environment of choice, but swiftly transition onerous tasks to q/kdb.</p>

<p>Thus PyKX allowed Emma to avoid the “with me or against me” mentality that comes with change. There was no unpopular abandonment of Python, far from it. Instead Python took on new meaning as it became the vehicle to steer more analytics into production and make those already in production much more perform. In fact, she soon appointed three of their top architects, Félix, Jesús, and Eloy, as team leads for three different teams responsible for various roles within the Mad Flow ecosystem utilizing the new infrastructure. These appointments align with the three different use cases for the PyKX library described in this post.</p>

<p>Stay tuned for the follow-up to this post, where Félix, Jesús, and Eloy will elaborate on the use case of heavy traffic and the utilization of PyKX!</p>

<h3 id="acknowledgments">Acknowledgments</h3>

<p>This post was greatly enhanced thanks to the edits and comments from Steve Wilcokson and Conor McCarthy from KX. Óscar Nydza, Juan M. Serrano, and Marcos Vázquez from Habla Computing did their best to finalize the draft left by Jesús before he started to enjoy his paternity leave to take care of Félix, Jesús, and Eloy.</p>

<h3 id="dedication">Dedication</h3>

<p>This post is dedicated to Eloy and the three newborns at Habla: Emma, Félix, and Jesús.</p>

<p><em>Post Picture: Project for “Destino”, Salvador Dalí (1946)</em></p>

        </div>

        <div class="tags">
            
        </div>

        
        
    </div>
</div>


    </div>
</section>
<section class="section">
    <div class="container">
        <div class="has-text-centered">
            <p>Theme built by <a href="https://www.csrhymes.com">C.S. Rhymes</a></p>
        </div>
    </div>
</section>
<script src="/assets/js/app.js" type="text/javascript"></script>
</body>
</html>

